{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MultiLabelBinarizer, Normalizer, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from sklearn.metrics import *\n",
    "import math\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class correlation_matrix():\n",
    "\n",
    "    def plot_correlation_heatmap(self, data_to_be_correlated):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "        plt.rcParams['font.size'] = 10\n",
    "        plt.figure(figsize = (16,10))\n",
    "\n",
    "        seaborn.heatmap(data_to_be_correlated.corr(), ax=ax, linecolor='white', cmap=\"coolwarm\", annot=True, fmt='.2f',\n",
    "                        annot_kws={\"size\": 6}, linewidths=.02, cbar_kws={\"orientation\": \"horizontal\"})\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kmeans_optimum_clusters_num():\n",
    "    \n",
    "    def kmeans_compute_metrics_for_every_cluster_number(self, clusters_range_lower_bound, clusters_range_upper_bound,\n",
    "                                                        dataset,\n",
    "                                                        distance_algorithm, print_optimum_metrics = True):\n",
    "\n",
    "        kmeans_list_metrics = []\n",
    "\n",
    "        for num_of_clusters in range(clusters_range_lower_bound, clusters_range_upper_bound):\n",
    "\n",
    "            kmeans = KMeans(n_clusters= int(num_of_clusters), init='k-means++', n_init=10,  random_state=42, verbose=0)\n",
    "            predictions = kmeans.fit_predict(dataset)\n",
    "            centers = kmeans.cluster_centers_\n",
    "            wcss = kmeans.inertia_\n",
    "            num_jobs = kmeans.n_iter_\n",
    "            silhouette = silhouette_score(dataset, predictions, distance_algorithm)\n",
    "\n",
    "            kmeans_list_metrics.append({'clusters': num_of_clusters, 'silhouette': silhouette,\n",
    "                                        'error': wcss, 'num_jobs': num_jobs})\n",
    "\n",
    "            if print_optimum_metrics is True:\n",
    "                print(\"For n_clusters = {}, silhouette score is {}, cluster_errors is {}, \"\n",
    "                      \"n_jobs {})\".format(num_of_clusters, silhouette, wcss, num_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class elbow_method_for_optimum_num_of_clusters():\n",
    "    def elbow_method(self, clusters_range_lower_bound, clusters_range_upper_bound, dataset):\n",
    "\n",
    "        wcss =[]\n",
    "\n",
    "        for num_clusters in range(clusters_range_lower_bound, clusters_range_upper_bound):\n",
    "            kmeans = KMeans(n_clusters=num_clusters, init='k-means++', n_init=10, verbose=0, random_state=42)\n",
    "            kmeans.fit(dataset)\n",
    "            wcss.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "        plt.plot(range(clusters_range_lower_bound, clusters_range_upper_bound), wcss)\n",
    "        plt.title('Elbow Method for '+ str(clustering_algorithm) +' Clustering')\n",
    "        plt.xlabel('No. of Cluster')\n",
    "        plt.ylabel('wcss: sum of distances or clustering cost of sample to their closest cluster center')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pca():\n",
    "\n",
    "    def __init__(self, dataset, final_variance_ratio, pca_plot_show=False):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.final_variance_ratio = final_variance_ratio\n",
    "\n",
    "        if pca_plot_show is True:\n",
    "            self.pca_plot()\n",
    "        else:\n",
    "            pass    \n",
    "    def pca_analysis(self):\n",
    "\n",
    "\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        self.array_of_dataset = self.standard_scaler.fit_transform(self.dataset)\n",
    "\n",
    "        self.pca = PCA()\n",
    "        self.pca.fit(self.array_of_dataset)\n",
    "\n",
    "\n",
    "        self.sum_of_variance_ratio = []\n",
    "\n",
    "        for feature_ratio_variance in self.pca.explained_variance_ratio_:\n",
    "            self.sum_of_variance_ratio.append(feature_ratio_variance)\n",
    "            if sum(self.sum_of_variance_ratio) >= float(self.final_variance_ratio):\n",
    "                break\n",
    "\n",
    "        self.optimum_num_pca_components = len(self.sum_of_variance_ratio)\n",
    "\n",
    "        self.pca_optimum = PCA(n_components=self.optimum_num_pca_components)\n",
    "        self.pca_optimum_num_features_array = self.pca_optimum.fit_transform(\n",
    "            self.array_of_dataset[:, : self.optimum_num_pca_components])\n",
    "\n",
    "        return self.pca_optimum_num_features_array\n",
    "\n",
    "    def pca_plot(self):\n",
    "\n",
    "        self.independent_variables = self.dataset\n",
    "        mean_vec = np.mean(self.independent_variables, axis=0)\n",
    "        self.covariance_matrix = np.cov(self.independent_variables.T)\n",
    "        self.eigenvalue_tuples, self.eigenvector_tuples = np.linalg.eig(self.covariance_matrix)\n",
    "        self.eig_pairs = [(np.abs(self.eigenvalue_tuples[index_number]), self.eigenvector_tuples[:, index_number]) for\n",
    "                          index_number in range(len(self.eigenvalue_tuples))]\n",
    "\n",
    "        self.eig_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        self.sum_eigenvalues = sum(self.eigenvalue_tuples)\n",
    "        self.individual_explained_variance = [(eigenvalue / self.sum_eigenvalues) * 100 for eigenvalue in\n",
    "                                              sorted(self.eigenvalue_tuples, reverse=True)]\n",
    "        self.cumulative_explained_variance = np.cumsum(self.individual_explained_variance)\n",
    "\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.bar(range(len(self.individual_explained_variance)), self.individual_explained_variance, alpha=0.3333,\n",
    "                align='center', label='individual explained variance', color='g')\n",
    "        plt.step(range(len(self.cumulative_explained_variance)), self.cumulative_explained_variance, where='mid',\n",
    "                 label='cumulative explained variance')\n",
    "        plt.ylabel('Explained variance ratio')\n",
    "        plt.xlabel('Principal components')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
